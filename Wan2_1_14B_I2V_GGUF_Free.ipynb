{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **WAN IMAGE TO VIDEO WITH Q4 & Q6 GGUF MODELS**\n",
        "- You can use the free T4 GPU to run this notebook with the default Q4 GGUF model. I recommend that you use higher GPUs for the Q6 GGUF model. This is the link to the main huggingface repository of the I2V 14B-480p GGUF models: https://huggingface.co/city96/Wan2.1-I2V-14B-480P-gguf/tree/main\n",
        "- Generating a video from this flux image (https://comfyanonymous.github.io/ComfyUI_examples/flux/) with the default settings (512x512, 20 steps, 49 frames) using the Q4 GGUF model and the free T4 GPU took about 26 minutes.\n",
        "- Generating a video from a 720x1280 Image with a setting of 480x832, 20 steps, and 33 frames using the Q4 GGUF model and the free T4 GPU took 26 minutes 30 seconds. Generating the same video using the Q6 GGUF model and the L4 GPU took 10 minutes 10 seconds.\n",
        "- The videos are generated at 16fps. You can use the `Frame Interpolation` notebook in this github repository (https://github.com/Isi-dev/Google-Colab_Notebooks) to increase it."
      ],
      "metadata": {
        "id": "_2gwCJ8f3mjA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t089iwSddWDL"
      },
      "outputs": [],
      "source": [
        "# @title Prepare Environment\n",
        "%cd /content\n",
        "\n",
        "!pip install -q torchsde einops diffusers accelerate xformers\n",
        "!pip install av\n",
        "!git clone https://github.com/Isi-dev/ComfyUI\n",
        "%cd /content/ComfyUI/custom_nodes\n",
        "!git clone https://github.com/Isi-dev/ComfyUI_GGUF.git\n",
        "%cd /content/ComfyUI/custom_nodes/ComfyUI_GGUF\n",
        "!pip install -r requirements.txt\n",
        "%cd /content/ComfyUI\n",
        "!apt -y install -qq aria2 ffmpeg\n",
        "\n",
        "useQ6 = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://civitai.com/api/download/models/1492795?type=Model&format=GGUF&size=pruned&fp=nf4 -d /content/ComfyUI/models/unet -o wan2.1-i2v-14b-480p-Q4_0.gguf\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors -d /content/ComfyUI/models/text_encoders -o umt5_xxl_fp8_e4m3fn_scaled.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors -d /content/ComfyUI/models/vae -o wan_2.1_vae.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/clip_vision/clip_vision_h.safetensors -d /content/ComfyUI/models/clip_vision -o clip_vision_h.safetensors\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gc\n",
        "import sys\n",
        "import random\n",
        "import os\n",
        "import imageio\n",
        "import subprocess\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML, Image as IPImage\n",
        "sys.path.insert(0, '/content/ComfyUI')\n",
        "\n",
        "from comfy import model_management\n",
        "\n",
        "from nodes import (\n",
        "    CheckpointLoaderSimple,\n",
        "    CLIPLoader,\n",
        "    CLIPTextEncode,\n",
        "    VAEDecode,\n",
        "    VAELoader,\n",
        "    KSampler,\n",
        "    UNETLoader,\n",
        "    LoadImage,\n",
        "    CLIPVisionLoader,\n",
        "    CLIPVisionEncode\n",
        ")\n",
        "\n",
        "from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF\n",
        "from comfy_extras.nodes_model_advanced import ModelSamplingSD3\n",
        "from comfy_extras.nodes_images import SaveAnimatedWEBP\n",
        "from comfy_extras.nodes_video import SaveWEBM\n",
        "from comfy_extras.nodes_wan import WanImageToVideo\n",
        "\n",
        "# Initialize nodes\n",
        "unet_loader = UnetLoaderGGUF()\n",
        "model_sampling = ModelSamplingSD3()\n",
        "clip_loader = CLIPLoader()\n",
        "clip_encode_positive = CLIPTextEncode()\n",
        "clip_encode_negative = CLIPTextEncode()\n",
        "vae_loader = VAELoader()\n",
        "clip_vision_loader = CLIPVisionLoader()\n",
        "clip_vision_encode = CLIPVisionEncode()\n",
        "load_image = LoadImage()\n",
        "wan_image_to_video = WanImageToVideo()\n",
        "ksampler = KSampler()\n",
        "vae_decode = VAEDecode()\n",
        "save_webp = SaveAnimatedWEBP()\n",
        "save_webm = SaveWEBM()\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.ipc_collect()\n",
        "    for obj in list(globals().values()):\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
        "            del obj\n",
        "    gc.collect()\n",
        "\n",
        "def save_as_mp4(images, filename_prefix, fps, output_dir=\"/content/ComfyUI/output\"):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.mp4\"\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "    with imageio.get_writer(output_path, fps=fps) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_webp(images, filename_prefix, fps, quality=90, lossless=False, method=4, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save images as animated WEBP using imageio.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.webp\"\n",
        "\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "\n",
        "    kwargs = {\n",
        "        'fps': int(fps),\n",
        "        'quality': int(quality),\n",
        "        'lossless': bool(lossless),\n",
        "        'method': int(method)\n",
        "    }\n",
        "\n",
        "    with imageio.get_writer(\n",
        "        output_path,\n",
        "        format='WEBP',\n",
        "        mode='I',\n",
        "        **kwargs\n",
        "    ) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_webm(images, filename_prefix, fps, codec=\"vp9\", quality=32, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save images as WEBM using imageio.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.webm\"\n",
        "\n",
        "\n",
        "    frames = [(img.cpu().numpy() * 255).astype(np.uint8) for img in images]\n",
        "\n",
        "\n",
        "    kwargs = {\n",
        "        'fps': int(fps),\n",
        "        'quality': int(quality),\n",
        "        'codec': str(codec),\n",
        "        'output_params': ['-crf', str(int(quality))]\n",
        "    }\n",
        "\n",
        "    with imageio.get_writer(\n",
        "        output_path,\n",
        "        format='FFMPEG',\n",
        "        mode='I',\n",
        "        **kwargs\n",
        "    ) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(frame)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "def save_as_image(image, filename_prefix, output_dir=\"/content/ComfyUI/output\"):\n",
        "    \"\"\"Save single frame as PNG image.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    output_path = f\"{output_dir}/{filename_prefix}.png\"\n",
        "\n",
        "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
        "\n",
        "    Image.fromarray(frame).save(output_path)\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def upload_image():\n",
        "    \"\"\"Handle image upload in Colab and store in /content/ComfyUI/input/\"\"\"\n",
        "    from google.colab import files\n",
        "    import os\n",
        "    import shutil\n",
        "\n",
        "    os.makedirs('/content/ComfyUI/input', exist_ok=True)\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move each uploaded file to ComfyUI input directory\n",
        "    for filename in uploaded.keys():\n",
        "        src_path = f'/content/ComfyUI/{filename}'\n",
        "        dest_path = f'/content/ComfyUI/input/{filename}'\n",
        "\n",
        "        shutil.move(src_path, dest_path)\n",
        "        print(f\"Image saved to: {dest_path}\")\n",
        "        return dest_path\n",
        "\n",
        "    return None\n",
        "\n",
        "def generate_video(\n",
        "    image_path: str = None,\n",
        "    positive_prompt: str = \"a cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit turning around\",\n",
        "    negative_prompt: str = \"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\",\n",
        "    width: int = 832,\n",
        "    height: int = 480,\n",
        "    seed: int = 82628696717253,\n",
        "    steps: int = 20,\n",
        "    cfg_scale: float = 1.0,\n",
        "    sampler_name: str = \"uni_pc\",\n",
        "    scheduler: str = \"simple\",\n",
        "    frames: int = 33,\n",
        "    fps: int = 16,\n",
        "    output_format: str = \"mp4\"\n",
        "):\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        print(\"Loading Text_Encoder...\")\n",
        "        clip = clip_loader.load_clip(\"umt5_xxl_fp8_e4m3fn_scaled.safetensors\", \"wan\", \"default\")[0]\n",
        "\n",
        "        positive = clip_encode_positive.encode(clip, positive_prompt)[0]\n",
        "        negative = clip_encode_negative.encode(clip, negative_prompt)[0]\n",
        "\n",
        "        del clip\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        if image_path is None:\n",
        "            print(\"Please upload an image file:\")\n",
        "            image_path = upload_image()\n",
        "        if image_path is None:\n",
        "            print(\"No image uploaded!\")\n",
        "        loaded_image = load_image.load_image(image_path)[0]\n",
        "        clip_vision = clip_vision_loader.load_clip(\"clip_vision_h.safetensors\")[0]\n",
        "        clip_vision_output = clip_vision_encode.encode(clip_vision, loaded_image, \"none\")[0]\n",
        "\n",
        "        del clip_vision\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        print(\"Loading VAE...\")\n",
        "        vae = vae_loader.load_vae(\"wan_2.1_vae.safetensors\")[0]\n",
        "\n",
        "        positive_out, negative_out, latent = wan_image_to_video.encode(\n",
        "            positive, negative, vae, width, height, frames, 1, loaded_image, clip_vision_output\n",
        "        )\n",
        "\n",
        "        print(\"Loading Unet Model...\")\n",
        "        if useQ6:\n",
        "            model = unet_loader.load_unet(\"wan2.1-i2v-14b-480p-Q6_K.gguf\")[0]\n",
        "        else:\n",
        "            model = unet_loader.load_unet(\"wan2.1-i2v-14b-480p-Q4_0.gguf\")[0]\n",
        "        model = model_sampling.patch(model, 8)[0]\n",
        "\n",
        "        print(\"Generating video...\")\n",
        "        sampled = ksampler.sample(\n",
        "            model=model,\n",
        "            seed=seed,\n",
        "            steps=steps,\n",
        "            cfg=cfg_scale,\n",
        "            sampler_name=sampler_name,\n",
        "            scheduler=scheduler,\n",
        "            positive=positive_out,\n",
        "            negative=negative_out,\n",
        "            latent_image=latent\n",
        "        )[0]\n",
        "\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        try:\n",
        "            print(\"Decoding latents...\")\n",
        "            decoded = vae_decode.decode(vae, sampled)[0]\n",
        "\n",
        "            del vae\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            output_path = \"\"\n",
        "            if frames == 1:\n",
        "                print(\"Single frame detected - saving as PNG image...\")\n",
        "                output_path = save_as_image(decoded[0], \"ComfyUI\")\n",
        "                # print(f\"Image saved as PNG: {output_path}\")\n",
        "\n",
        "                display(IPImage(filename=output_path))\n",
        "            else:\n",
        "                if output_format.lower() == \"webm\":\n",
        "                    print(\"Saving as WEBM...\")\n",
        "                    output_path = save_as_webm(\n",
        "                        decoded,\n",
        "                        \"ComfyUI\",\n",
        "                        fps=fps,\n",
        "                        codec=\"vp9\",\n",
        "                        quality=10\n",
        "                    )\n",
        "                elif output_format.lower() == \"mp4\":\n",
        "                    print(\"Saving as MP4...\")\n",
        "                    output_path = save_as_mp4(decoded, \"ComfyUI\", fps)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unsupported output format: {output_format}\")\n",
        "\n",
        "                # print(f\"Video saved as {output_format.upper()}: {output_path}\")\n",
        "\n",
        "                display_video(output_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during decoding/saving: {str(e)}\")\n",
        "            raise\n",
        "        finally:\n",
        "            clear_memory()\n",
        "\n",
        "def display_video(video_path):\n",
        "    from IPython.display import HTML\n",
        "    from base64 import b64encode\n",
        "\n",
        "    video_data = open(video_path,'rb').read()\n",
        "\n",
        "    # Determine MIME type based on file extension\n",
        "    if video_path.lower().endswith('.mp4'):\n",
        "        mime_type = \"video/mp4\"\n",
        "    elif video_path.lower().endswith('.webm'):\n",
        "        mime_type = \"video/webm\"\n",
        "    elif video_path.lower().endswith('.webp'):\n",
        "        mime_type = \"image/webp\"\n",
        "    else:\n",
        "        mime_type = \"video/mp4\"  # default\n",
        "\n",
        "    data_url = f\"data:{mime_type};base64,\" + b64encode(video_data).decode()\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "    <video width=512 controls autoplay loop>\n",
        "        <source src=\"{data_url}\" type=\"{mime_type}\">\n",
        "    </video>\n",
        "    \"\"\"))\n",
        "\n",
        "print(\"✅ Environment Setup Complete!\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate Video\n",
        "\n",
        "positive_prompt = \"A cute anime girl with massive fennec ears and a big fluffy tail wearing a maid outfit turning around.\" # @param {\"type\":\"string\"}\n",
        "negative_prompt = \"色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走\" # @param {\"type\":\"string\"}\n",
        "width = 512 # @param {\"type\":\"number\"}\n",
        "height = 512 # @param {\"type\":\"number\"}\n",
        "seed = 0 # @param {\"type\":\"integer\"}\n",
        "steps = 20 # @param {\"type\":\"integer\", \"min\":1, \"max\":100}\n",
        "cfg_scale = 3 # @param {\"type\":\"number\", \"min\":1, \"max\":20}\n",
        "sampler_name = \"uni_pc\" # @param [\"uni_pc\", \"euler\", \"dpmpp_2m\", \"ddim\", \"lms\"]\n",
        "scheduler = \"simple\" # @param [\"simple\", \"normal\", \"karras\", \"exponential\"]\n",
        "frames = 49 # @param {\"type\":\"integer\", \"min\":1, \"max\":120}\n",
        "fps = 16 # @param {\"type\":\"integer\", \"min\":1, \"max\":60}\n",
        "output_format = \"mp4\" # @param [\"mp4\", \"webm\"]\n",
        "\n",
        "import random\n",
        "seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "# with torch.inference_mode():\n",
        "generate_video(\n",
        "    image_path=None,\n",
        "    positive_prompt=positive_prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    width=width,\n",
        "    height=height,\n",
        "    seed=seed,\n",
        "    steps=steps,\n",
        "    cfg_scale=cfg_scale,\n",
        "    sampler_name=sampler_name,\n",
        "    scheduler=scheduler,\n",
        "    frames=frames,\n",
        "    fps=fps,\n",
        "    output_format=output_format\n",
        ")\n",
        "clear_memory()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wo8w6tKerJMJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}